# -*- coding: utf-8 -*-
"""Lepto_CCHAIN_EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cnAcyJIljKLEVXQ0KBrAdTMv4Ii6x7XR

# Initialization
"""

# general libraries
import re
import time
import json
import pickle
import warnings
import numpy as np
import pandas as pd
from tqdm.notebook import tqdm
from collections import Counter
from sklearn.preprocessing import MinMaxScaler
warnings.filterwarnings("ignore")

# visualizations
import seaborn as sns
from termcolor import colored
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import plotly.graph_objects as go

# mount gdrive
from google.colab import drive
drive.mount('/content/drive')

"""# Feature Selection

## Location
"""

brgy = pd.read_csv('/content/drive/MyDrive/Project CCHAIN/brgy_geography.csv')
brgy.head()

brgy.nunique()

loc = pd.read_csv('/content/drive/MyDrive/Project CCHAIN/location.csv')
loc.head()

loc.nunique()

map = pd.merge(brgy, loc, on='adm4_pcode')
map.head()

map = map.drop(columns=['brgy_total_area_y'])
map.rename(columns={"brgy_total_area_x": "brgy_total_area"}, inplace=True)
map.head()

"""## Health & Climate

Dropping the following variables:

**Wind Speed (wind_speed):**

Relevance: Low to Moderate. Wind might affect the distribution of contaminated water, but this is usually a secondary factor.

**Solar Radiation (solar_rad), UV Radiation (uv_rad):**

Relevance: Low to Moderate. Higher levels of UV radiation might reduce bacterial survival in the environment.

**CO, NO2, O3, PM10, PM25, SO2:**

Relevance: Low. These pollutants are more directly related to respiratory conditions than to leptospirosis. However, they might indirectly influence the overall environment.

**NDVI (Normalized Difference Vegetation Index):**

Relevance: Low to Moderate. NDVI indicates vegetation density, which could indirectly influence rodent populations, a primary vector for leptospirosis.

**Summary of Highly Relevant Factors:**
* Precipitation (pr)
* Relative Humidity (rh)
* Temperature (tave, tmax, tmin)
* Heat Index (heat_index)

These factors are crucial as they influence the conditions under which the leptospirosis bacteria thrive and are transmitted to humans.
"""

lepto_df = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/lepto_df.csv')
lepto_df.head()

lepto_df.nunique()

lepto_df = pd.merge(lepto_df, map[['adm3_en', 'adm3_pcode']], on='adm3_en', how='left')

# Dropping the specified columns
columns_to_drop = ['wind_speed', 'solar_rad', 'uv_rad', 'co', 'no2', 'o3', 'pm10', 'pm25', 'so2', 'ndvi']
lepto_df = lepto_df.drop(columns=columns_to_drop)

# Checking the first few rows to confirm the columns have been dropped
lepto_df.head()

lepto_df.nunique()

"""## Environment
The environment data is from Project Noah Hazards. This data is measured on 2015 and is mapped out on 879 barangays.

The suitable method of aggregation is simple average for city-level data. The values for the hazards will be assumed constant from 2010-2022 to be able to merge it with the Health & Climate Data.
"""

noah = pd.read_csv('/content/drive/MyDrive/Project CCHAIN/project_noah_hazards.csv')
noah.head()

noah.nunique()

noah = noah.drop(columns=['uuid','freq','pct_area_landslide_hazard_low','pct_area_landslide_hazard_med','pct_area_landslide_hazard_high'])

noah.head()

noah_city = pd.merge(noah, map[['adm4_pcode', 'adm3_pcode']], on='adm4_pcode', how='left')
noah_city.nunique()

noah_city = noah_city.drop(columns=['adm4_pcode', 'date'])

noah_city = noah_city.groupby('adm3_pcode').mean().reset_index()
noah_city.head()

noah_city.nunique()

"""## Socioeconomic
The socioeconomic data considered is population.

Methods of aggregation: pop_count_total - sum

"""

pop = pd.read_csv('/content/drive/MyDrive/Project CCHAIN/worldpop_population.csv')
pop.head()

pop.nunique()

pop = pop.drop(columns=['uuid', 'freq','pop_count_mean','pop_count_median','pop_count_stdev','pop_count_min','pop_count_max','pop_density_mean','pop_density_median','pop_density_stdev','pop_density_min','pop_density_max'])
pop.head()

pop_city = pd.merge(pop, map[['adm4_pcode', 'adm3_pcode', 'brgy_total_area']], on='adm4_pcode', how='left')
pop_city.head()

pop_city = pop_city.drop(columns=['adm4_pcode'])

pop_city =  pop_city.groupby(['date', 'adm3_pcode']).agg({'pop_count_total': 'sum','brgy_total_area': 'sum'}).reset_index()
pop_city.head()

pop_city.nunique()

# Step 1: Check the unique pairings
unique_pairs = pop_city[['adm3_pcode', 'brgy_total_area']].drop_duplicates()
print(unique_pairs)

# Step 2: Count the unique pairings
unique_counts = pop_city.groupby('adm3_pcode')['brgy_total_area'].nunique().reset_index()
unique_counts.columns = ['adm3_pcode', 'unique_brgy_total_area']
print(unique_counts)

# Step 3: Identify problematic pairings (if any adm3_pcode has more than 1 unique brgy_total_area)
problematic_areas = unique_counts[unique_counts['unique_brgy_total_area'] > 1]
print(problematic_areas)

# Manually update the brgy_total_area for the specified adm3_pcode
pop_city.loc[pop_city['adm3_pcode'] == 'PH137503000', 'brgy_total_area'] = 10.5395

pop_city.nunique()

pop_city.rename(columns={"brgy_total_area": "city_area"}, inplace=True)
pop_city['pop_density']=pop_city['pop_count_total']/pop_city['city_area']
pop_city.head()

"""## Merging"""

lepto_df = pd.merge(lepto_df, noah_city, on='adm3_pcode', how='left')
lepto_df.head()

# Step 1: Extract the year from the date columns
lepto_df['year'] = pd.to_datetime(lepto_df['date']).dt.year
pop_city['year'] = pd.to_datetime(pop_city['date']).dt.year

lepto_df.head()

pop_city.head()

lepto_df = lepto_df.merge(pop_city[['year', 'adm3_pcode', 'pop_count_total','pop_density']],
                          on=['year', 'adm3_pcode'],
                          how='left')

lepto_df.head()

# Check for missing values in pop_count_total
missing_values = lepto_df[lepto_df['pop_count_total'].isna()]

# Display the unique years with missing values
missing_years = missing_values['year'].unique()

print(missing_years)

lepto_df = lepto_df.drop(columns=['year', 'adm3_pcode'])

lepto_df.head()

lepto_df.nunique()

"""## Preprocessing"""

num_duplicates = lepto_df.duplicated().sum()
print(f'Number of duplicate rows: {num_duplicates}')

lepto_df.drop_duplicates(inplace=True)

lepto_df.info()

#Limit the date range because there are no population data fro years 2021 and 2022

lepto_df['date'] = pd.to_datetime(lepto_df['date'], errors='coerce')

lepto_df = lepto_df[(lepto_df['date'].dt.year >= 2008) & (lepto_df['date'].dt.year <= 2020)]

lepto_df.info()

# Clean the 'adm3_en' column by removing 'City', 'City of', and trailing 'City'
lepto_df['adm3_en'] = lepto_df['adm3_en'].str.replace('^City of ', '', regex=True)
lepto_df['adm3_en'] = lepto_df['adm3_en'].str.replace('^City ', '', regex=True)
lepto_df['adm3_en'] = lepto_df['adm3_en'].str.replace(' City$', '', regex=True)

lepto_df['adm3_en'].value_counts()

# Save the results DataFrame to a CSV file in Google Drive
file_path = '/content/drive/MyDrive/Leptospirosis CCHAIN/lepto_dfclean.csv'
lepto_df.to_csv(file_path, index=False)

"""# EDA"""

lepto_df = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/lepto_dfclean.csv')
lepto_df.head()

"""## Cases"""

# Convert 'date' column to datetime
lepto_df['date'] = pd.to_datetime(lepto_df['date'])

# 1. Sum of cases for the whole dataset
total_cases = lepto_df['case_total'].sum()

# 2. Sum of cases per city for the whole dataset
total_cases_per_city = lepto_df.groupby('adm3_en')['case_total'].sum()

# 3. Sum of cases per city per year
cases_per_city_per_year = lepto_df.groupby([lepto_df['date'].dt.year, 'adm3_en'])['case_total'].sum().unstack()

# 4. Sum of cases per city per month
cases_per_city_per_month = lepto_df.groupby([lepto_df['date'].dt.to_period('M'), 'adm3_en'])['case_total'].sum().unstack()

# Save the results as CSV files in Google Drive
total_cases_per_city.to_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/total_cases_per_city.csv', index=True)
cases_per_city_per_year.to_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/cases_per_city_per_year.csv', index=True)
cases_per_city_per_month.to_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/cases_per_city_per_month.csv', index=True)

"""### Total Cases"""

lepto_df = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/lepto_dfclean.csv')
lepto_df.head()

lepto_df.shape

lepto_df['case_total'].sum()

# Count the occurrences of cases with and without cases
case_counts = lepto_df['case_total'].apply(lambda x: 'With Case' if x > 0 else 'Without Case').value_counts()

# Calculate percentages
total_counts = case_counts.sum()
percentages = (case_counts / total_counts * 100).round(2)

# Print the percentages
print(f"Percentage of With Case: {percentages['With Case']}%")
print(f"Percentage of Without Case: {percentages['Without Case']}%")

# Plotting the bar graph
plt.figure(figsize=(10, 6))

# Define bar positions and width
bar_positions = np.arange(len(case_counts))
bar_width = 0.7  # Reduced width for closer bars

# Plot bars
plt.bar(bar_positions, case_counts.values, color='#19535B', width=bar_width)

# Customize x-axis
plt.xticks(bar_positions, case_counts.index)

# Removing gridlines
plt.grid(False)

# Show plot
plt.show()

total = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/total_cases_per_city.csv')
print(total)

# Sort the DataFrame by 'case_total' in descending order
total_sorted = total.sort_values(by='case_total', ascending=False)

# Clean the 'adm3_en' column by removing 'City', 'City of', and trailing 'City'
total_sorted['adm3_en'] = total_sorted['adm3_en'].str.replace('^City of ', '', regex=True)
total_sorted['adm3_en'] = total_sorted['adm3_en'].str.replace('^City ', '', regex=True)
total_sorted['adm3_en'] = total_sorted['adm3_en'].str.replace(' City$', '', regex=True)

# Display the cleaned DataFrame
print("\nCleaned and Sorted Data (Highest to Lowest):")
print(total_sorted)

# Sort the DataFrame by 'case_total' in descending order
total_sorted = total.sort_values(by='case_total', ascending=False)

# Define colors: Top 3 highlighted, rest in gray
colors = ['#19535B' if i < 3 else 'gray' for i in range(len(total_sorted))]

# Create a horizontal bar plot
plt.figure(figsize=(12, 8))
bars = plt.barh(total_sorted['adm3_en'], total_sorted['case_total'], color=colors)
plt.gca().invert_yaxis()  # To have the highest values at the top

# Add value labels beside the bars
for bar in bars:
    width = bar.get_width()
    plt.text(width + (width * 0.01), bar.get_y() + bar.get_height()/2, f'{int(width)}',
             va='center', ha='left', fontsize=12, color='black')

# Customize font sizes
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)

# Adjust the plot margins to create space around the plot area
plt.margins(x=0.07, y=0.05)  # Adjust margins as needed

# Show the plot
plt.tight_layout()
plt.show()

"""### Yearly Cases"""

yearly = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/cases_per_city_per_year.csv')
yearly.head()

# Ensure the 'date' column is in datetime format and set it as the index
yearly['date'] = pd.to_datetime(yearly['date'], format='%Y')
yearly.set_index('date', inplace=True)

# Extract year from the 'date' index
yearly['year'] = yearly.index.year

# Calculate the sum of cases per year for each city
yearly_sum = yearly.groupby(['year']).sum()

# Initialize a list to store the results
results = []

# Calculate total cases for each city
total_cases = yearly_sum.sum()

# Find the top 3 years with the highest total number of cases for each city
for city in yearly_sum.columns:
    top_3 = yearly_sum[city].nlargest(3)
    top_3_years = ', '.join(top_3.index.astype(str))
    top_3_sums = ', '.join(f'{total:.2f}' for total in top_3.values)
    sum_top_3 = top_3.sum()
    top_3_sum_avg = top_3.mean()

    # Calculate percentage of the top 3 years' sum out of total cases
    total = total_cases[city]
    percentage_top_3 = (sum_top_3 / total) * 100 if total > 0 else 0

    results.append({
        'City': city,
        'Top 3 Years': top_3_years,
        'Top 3 Sums': top_3_sums,
        'Sum of Top 3 Years': f'{sum_top_3:.2f}',
        'Percentage of Top 3 Years': f'{percentage_top_3:.2f}%'
    })

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Sort DataFrame by 'Sum of Top 3 Years' in descending order
results_df['Sum of Top 3 Years'] = results_df['Sum of Top 3 Years'].astype(float)
results_df.sort_values(by='Sum of Top 3 Years', ascending=False, inplace=True)

# Save the results DataFrame to a CSV file in Google Drive
file_path = '/content/drive/MyDrive/Leptospirosis CCHAIN/top_3_years_summary.csv'
results_df.to_csv(file_path, index=False)

yearlytop3 = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/top_3_years_summary.csv')
yearlytop3.head(12)

yearly = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/cases_per_city_per_year.csv')

# Sum the cases for all cities per year
yearly['total_cases'] = yearly.drop(columns='date').sum(axis=1)

# Keep only 'date' and 'total_cases' columns
yearly = yearly[['date', 'total_cases']]

# Rename 'date' column to 'year'
yearly.rename(columns={'date': 'year'}, inplace=True)

# Sort the DataFrame by 'total_cases' in descending order to find the top 3
yearly_sorted = yearly.sort_values('total_cases', ascending=False)

# Get the top 3 years
top_3_years = yearly_sorted['year'].iloc[:3].values

# Define colors: top 3 in a specific color, others in gray
colors = ['#19535B' if year in top_3_years else 'gray' for year in yearly['year']]

# Plotting the bar graph
plt.figure(figsize=(10, 6))
plt.bar(yearly['year'], yearly['total_cases'], color=colors)
plt.xticks(yearly['year'])  # Set x-ticks to match the years
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.tight_layout()
plt.show()

yearly = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/cases_per_city_per_year.csv')

# Set 'date' column as the index
yearly.set_index('date', inplace=True)

# Plot the time series for each city
plt.figure(figsize=(14, 8))

for city in yearly.columns:
    plt.plot(yearly.index, yearly[city], marker='o', label=city)

plt.title('Time Series of Leptospirosis Cases by City')
plt.xlabel('Year')
plt.ylabel('Number of Cases')
plt.legend(loc='upper left', bbox_to_anchor=(1, 1))
plt.grid(True)
plt.tight_layout()

# Show the plot
plt.show()

yearly = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/cases_per_city_per_year.csv')

# Set 'date' column as the index
yearly.set_index('date', inplace=True)

# Create and display a plot for each city
for city in yearly.columns:
    plt.figure(figsize=(10, 6))
    plt.plot(yearly.index, yearly[city], marker='o', label=city)
    plt.title(f'Yearly Leptospirosis Cases in {city}')
    plt.xlabel('Year')
    plt.ylabel('Number of Cases')
    plt.grid(True)
    plt.tight_layout()

    # Show the plot
    plt.show()

"""### Monthly Cases"""

monthly = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/cases_per_city_per_month.csv')
monthly.head()

# Ensure the 'date' column is in datetime format and set it as the index
monthly['date'] = pd.to_datetime(monthly['date'], format='%Y-%m')
monthly.set_index('date', inplace=True)

# Extract month from the 'date' index
monthly['month'] = monthly.index.month

# Calculate the sum of cases per month for each city
monthly_sum = monthly.groupby(['month']).sum()

# Initialize a list to store the results
results = []

# Calculate total cases for each city
total_cases = monthly_sum.sum()

# Find the top 3 months with the highest total number of cases for each city
for city in monthly_sum.columns:
    top_3 = monthly_sum[city].nlargest(3)
    top_3_months = ', '.join(top_3.index.astype(str))
    top_3_sums = ', '.join(f'{total:.2f}' for total in top_3.values)
    sum_top_3 = top_3.sum()
    top_3_sum_avg = top_3.mean()

    # Calculate percentage of the top 3 months' sum out of total cases
    total = total_cases[city]
    percentage_top_3 = (sum_top_3 / total) * 100 if total > 0 else 0

    results.append({
        'City': city,
        'Top 3 Months': top_3_months,
        'Top 3 Sums': top_3_sums,
        'Sum of Top 3 Months': f'{sum_top_3:.2f}',
        'Percentage of Top 3 Months': f'{percentage_top_3:.2f}%'
    })

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Sort DataFrame by 'Sum of Top 3 Months' in descending order
results_df['Sum of Top 3 Months'] = results_df['Sum of Top 3 Months'].astype(float)
results_df.sort_values(by='Sum of Top 3 Months', ascending=False, inplace=True)

# Save the results DataFrame to a CSV file in Google Drive
file_path = '/content/drive/MyDrive/Leptospirosis CCHAIN/top_3_months_summary.csv'
results_df.to_csv(file_path, index=False)

monthly = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/top_3_months_summary.csv')
monthly.head(12)

monthly = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/cases_per_city_per_month.csv')

# Ensure the 'date' column is in datetime format and set it as the index
monthly['date'] = pd.to_datetime(monthly['date'], format='%Y-%m')
monthly.set_index('date', inplace=True)

# Create and display a plot for each city
for city in monthly.columns:
    plt.figure(figsize=(10, 6))
    plt.plot(monthly.index, monthly[city], label=city, color='#19535B')
    plt.title(f'Monthly Leptospirosis Cases in  {city}')
    plt.xlabel('Date')
    plt.ylabel('Number of Cases')
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.grid(True)
    plt.tight_layout()
    # Add faint gridlines with thin lines
    plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray', alpha=0.3)

    # Show the plot
    plt.show()

monthly = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/cases_per_city_per_month.csv')

# Isolate the data for Iloilo City between the years 2011 and 2012
iloilo_data = monthly[(monthly['date'] >= '2011-01') & (monthly['date'] <= '2013-12')][['date', 'Iloilo']]

# Append rows for Dec 2010 and Jan 2013 with NaN values for plotting purposes
additional_dates = pd.to_datetime(['2010-12', '2013-01'])
additional_data = pd.DataFrame({'date': additional_dates, 'Iloilo': [None, None]})

# Concatenate the original data with the additional dates
iloilo_data = pd.concat([additional_data, iloilo_data])

# Convert the 'date' column to datetime format
iloilo_data['date'] = pd.to_datetime(iloilo_data['date'])

# Set the 'date' column as the index
iloilo_data.set_index('date', inplace=True)

# Plot the graph
plt.figure(figsize=(12, 8))
plt.plot(iloilo_data.index, iloilo_data['Iloilo'], marker='o',color='#19535B')

# Format the x-axis to show all months with 3-letter abbreviations, without the year
plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.MonthLocator())  # Show all months
plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%b'))

# Ensure the plot includes Dec 2010 and Jan 2013 but does not label them
plt.xlim(pd.Timestamp('2010-12-01'), pd.Timestamp('2013-01-31'))

# Rotate x-axis labels to prevent overlap
plt.xticks(rotation=45, ha='right', fontsize = 12)

# Adjust the y-axis and partition it by 50s
plt.ylim(0, iloilo_data['Iloilo'].max() + 50)
plt.yticks(range(0, int(iloilo_data['Iloilo'].max() + 50), 50), fontsize = 12)

# Add faint gridlines with thin lines
plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray', alpha=0.2)

# Show the plot
plt.show()

"""## Descriptive Statistics
* date - standard date aggregated weekly

* case_total - Number of recorded disease cases. May be suspected, probable, or confirmed.

* heat_index - Apparent temperature (째C) derived from air temperature and relative humidity. Extracted from ERA5.

* pr - Rainfall estimates (mm/day) from rain gauge and satellite observations. Extracted from CHIRPS. Barangay Tumalutab (Zamboanga) has no data.

* rh - Water vapor pressure (%) at which the air becomes saturated (i.e., water vapor begins to condense into liquid water). Extracted from ERA5.

* tave	- Average temperature (째C) of air at 2m above the surface of land, sea, or inland waters. Extracted from ERA5.

* tmax - Maximum temperature (째C) of air at 2m above the surface of land, sea, or inland waters. Extracted from ERA5.

* tmin - Minimum temperature (째C) of air at 2m above the surface of land, sea, or inland waters. Extracted from ERA5.

* pct_area_flood_hazard_100yr_low	- Area proportion of the barangay, ranging from 0-100 percent, that is potentially affected by a low hazard flood within a 100 year rain return period

* pct_area_flood_hazard_100yr_med	- Area proportion of the barangay, ranging from 0-100 percent, that is potentially affected by a medium hazard flood within a 100 year rain return period

* pct_area_flood_hazard_100yr_high - Area proportion of the barangay, ranging from 0-100 percent, that is potentially affected with a high flood hazard within a 100 year rain return period

* pct_area_flood_hazard_25yr_low - Area proportion of the barangay, ranging from 0-100 percent, that is potentially affected by a low hazard flood
within a 25 year rain return period

* pct_area_flood_hazard_25yr_med - 	Area proportion of the barangay, ranging from 0-100 percent, that is potentially affected by a medium hazard flood within a 25 year rain return period

* pct_area_flood_hazard_25yr_high	- Area proportion of the barangay, ranging from 0-100 percent, that is potentially affected with a high flood hazard within a 25 year rain return period

* pct_area_flood_hazard_5yr_low	- Area proportion of the barangay, ranging from 0-100 percent, that is potentially affected with a high flood hazard within a 5 year rain return period

* pct_area_flood_hazard_5yr_med	- Area proportion of the barangay, ranging from 0-100 percent, that is potentially affected by a medium hazard flood within a 5 year rain return period

* pct_area_flood_hazard_5yr_high	- Area proportion of the barangay, ranging from 0-100 percent, that is potentially affected with a high flood hazard within a 5 year rain return period

Des
"""

lepto_df.head()

lepto_df.describe()

# Sort by 'pop_count_total' and drop duplicates
sorted_by_pop_count = lepto_df.sort_values(by='pop_count_total', ascending=False).drop_duplicates()

# Sort by 'pop_density' and drop duplicates
sorted_by_pop_density = lepto_df.sort_values(by='pop_density', ascending=False).drop_duplicates()

# Define histogram color and gridline style
hist_color = '#19535B'
rest_color = 'gray'

# Define a custom color palette
def color_palette(df, column):
    top_3_indices = df.head(3).index
    colors = [hist_color if i in top_3_indices else rest_color for i in df.index]
    return colors

# Plot horizontal bar graph for 'pop_count_total'
plt.figure(figsize=(12, 8))
palette = color_palette(sorted_by_pop_count, 'pop_count_total')
sns.barplot(y=sorted_by_pop_count['adm3_en'], x=sorted_by_pop_count['pop_count_total'], palette=palette)
plt.xticks(fontsize=18)
plt.yticks(fontsize=18)
plt.show()

# Plot horizontal bar graph for 'pop_density'
plt.figure(figsize=(12, 8))
palette = color_palette(sorted_by_pop_density, 'pop_density')
sns.barplot(y=sorted_by_pop_density['adm3_en'], x=sorted_by_pop_density['pop_density'], palette=palette)
plt.xticks(fontsize=18)
plt.yticks(fontsize=18)
plt.show()

# Exclude the specified columns and non-numeric columns for histogram plotting
exclude_columns = [
    'date', 'adm3_en',
    'pct_area_flood_hazard_100yr_low', 'pct_area_flood_hazard_100yr_med', 'pct_area_flood_hazard_100yr_high',
    'pct_area_flood_hazard_25yr_low', 'pct_area_flood_hazard_25yr_med', 'pct_area_flood_hazard_25yr_high',
    'pct_area_flood_hazard_5yr_low', 'pct_area_flood_hazard_5yr_med', 'pct_area_flood_hazard_5yr_high'
]
numeric_columns = [col for col in lepto_df.columns if col not in exclude_columns]

# Define the number of columns for the subplot grid
num_columns = 3  # Adjust as needed

# Calculate the total number of plots needed
total_plots = len(numeric_columns)

# Determine the number of rows needed
num_rows = int(np.ceil(total_plots / num_columns))

# Create a subplot grid with enough space for all plots
fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(num_columns * 5, num_rows * 4), constrained_layout=True)

# Flatten the axes array for easy iteration
axes = axes.flatten()

# Define histogram color and gridline style
hist_color = '#19535B'
gridline_style = '--'
gridline_width = 0.5

# Plot histograms for each numeric column
for i, column in enumerate(numeric_columns):
    if i < len(axes):
        ax = axes[i]
        city_data = lepto_df[column]
        ax.hist(city_data, bins=30, color=hist_color)
        ax.set_title(f'Histogram of {column}')
        ax.set_xlabel(column)
        ax.set_ylabel('Frequency')
        ax.grid(True, linestyle=gridline_style, linewidth=gridline_width)

# Hide any unused subplots
for i in range(len(numeric_columns), len(axes)):
    axes[i].axis('off')

# Show the plot
plt.show()

# Get unique cities
cities = lepto_df['adm3_en'].unique()

# Define the columns to exclude
exclude_columns = [
    'date', 'adm3_en',
    'pct_area_flood_hazard_100yr_low', 'pct_area_flood_hazard_100yr_med', 'pct_area_flood_hazard_100yr_high',
    'pct_area_flood_hazard_25yr_low', 'pct_area_flood_hazard_25yr_med', 'pct_area_flood_hazard_25yr_high',
    'pct_area_flood_hazard_5yr_low', 'pct_area_flood_hazard_5yr_med', 'pct_area_flood_hazard_5yr_high'
]

# Filter out columns to include only the desired numeric columns
numeric_columns = [col for col in lepto_df.columns if col not in exclude_columns]

# Define histogram color and gridline style
hist_color = '#19535B'
gridline_style = '--'
gridline_width = 0.5

# Loop through each feature to create separate plots
for column in numeric_columns:
    # Define the number of columns for the subplot grid
    num_columns = 3  # Adjust as needed

    # Calculate the total number of plots needed
    total_plots = len(cities)

    # Determine the number of rows needed
    num_rows = int(np.ceil(total_plots / num_columns))

    # Create a subplot grid with enough space for all plots
    fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(num_columns * 5, num_rows * 4), constrained_layout=True)

    # Flatten the axes array for easy iteration
    axes = axes.flatten()

    # Plot histograms for the current feature across all cities
    for i, city in enumerate(cities):
        if i < len(axes):
            ax = axes[i]  # Position the histogram in the correct subplot
            city_data = lepto_df[lepto_df['adm3_en'] == city]
            ax.hist(city_data[column], bins=30, color=hist_color)
            ax.set_title(f'{column} in {city}')
            ax.set_xlabel(column)
            ax.set_ylabel('Frequency')
            ax.grid(True, linestyle=gridline_style, linewidth=gridline_width)

    # Hide any unused subplots
    for i in range(len(cities), len(axes)):
        axes[i].axis('off')

    # Show the plot for the current feature
    plt.show()

"""## Correlation"""

lepto_df = pd.read_csv('/content/drive/MyDrive/Leptospirosis CCHAIN/lepto_dfclean.csv')
lepto_df.head()

# Drop the 'adm3_pcode' and 'date' columns
lepto_df_filtered = lepto_df.drop(columns=['adm3_en', 'date'])

# Compute the correlation matrix
correlation_matrix = lepto_df_filtered.corr()

# Extract the correlation of features with 'case_total'
correlation_with_cases = correlation_matrix['case_total'].sort_values(ascending=False)

# Display the correlation with 'case_total' and the full correlation matrix
correlation_with_cases, correlation_matrix

# Drop 'case_total' from the correlation series
correlation_with_cases = correlation_with_cases.drop('case_total')

# Plotting the correlation with 'case_total'
plt.figure(figsize=(10, 6))
bars = correlation_with_cases.plot(kind='bar', color='#19535B')

# Adding values on the bars
for bar in bars.patches:
    height = bar.get_height()
    if height >= 0:
        # Positive correlations: place text on top of the bar
        plt.text(
            bar.get_x() + bar.get_width() / 2,  # x position
            height,  # y position
            f'{height:.2f}',  # text to display
            ha='center',  # horizontal alignment
            va='bottom',  # vertical alignment
            fontsize=10,  # font size
            color='black'  # text color
        )
    else:
        # Negative correlations: place text below the bar
        plt.text(
            bar.get_x() + bar.get_width() / 2,  # x position
            height,  # y position
            f'{height:.2f}',  # text to display
            ha='center',  # horizontal alignment
            va='top',  # vertical alignment
            fontsize=10,  # font size
            color='black'  # text color
        )

plt.title('Correlation of Features with case_total')
plt.xticks(rotation=45, ha='right', fontsize=12)  # Rotate x-axis labels for better readability
plt.yticks(fontsize=12)
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

# List of temperature-related columns and 'case_total'
columns_of_interest = ['heat_index', 'tave', 'tmax', 'tmin', 'rh', 'pr', 'case_total']

# Filter the DataFrame to include only these columns
filtered_df = lepto_df[columns_of_interest]

# Compute the correlation matrix
correlation_matrix = filtered_df.corr()

# Create a grid of subplots
fig, axes = plt.subplots(len(columns_of_interest), len(columns_of_interest), figsize=(15, 15))

# Iterate over each pair of columns to create scatter plots
for i, feature1 in enumerate(columns_of_interest):
    for j, feature2 in enumerate(columns_of_interest):
        ax = axes[i, j]

        if i == j:
            # Diagonal: Use a density plot
            sns.kdeplot(data=filtered_df, x=feature1, ax=ax)
            ax.set_xlabel(feature1)
            ax.set_ylabel(feature1)
        else:
            # Off-diagonal: Scatter plot with correlation coefficient
            sns.scatterplot(x=filtered_df[feature1], y=filtered_df[feature2], ax=ax)
            correlation = correlation_matrix.loc[feature1, feature2]
            ax.set_title(f'Corr: {correlation:.2f}', fontsize=8)
            ax.set_xlabel(feature1)
            ax.set_ylabel(feature2)

        # Optional: Adjust axis labels and title
        ax.set_xticks([])
        ax.set_yticks([])

plt.tight_layout()
plt.show()

# Print the correlation matrix for reference
print("Correlation Matrix:")
print(correlation_matrix)

"""## Time Series"""

# Convert 'date' column to datetime format (if not already done)
lepto_df['date'] = pd.to_datetime(lepto_df['date'])

# Set the 'date' column as the index
lepto_df.set_index('date', inplace=True)

# Assuming lepto_df is your DataFrame and it's already prepared
# Get the unique city names
cities = lepto_df['adm3_en'].unique()

# Loop through each city and create a separate plot
for city in cities:
    # Filter the dataframe for the specific city
    city_data = lepto_df[lepto_df['adm3_en'] == city]

    # Set up the figure
    plt.figure(figsize=(10, 6))

    # Plot Leptospirosis cases over time for this city
    plt.plot(city_data.index, city_data['case_total'], label=city, color='#19535B')
    plt.title(f'Leptospirosis Cases Over Time in {city}', fontsize=14)
    plt.ylabel('Number of Cases', fontsize=12)
    plt.xlabel('Date', fontsize=12)

    # Format the x-axis to show dates by year
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
    plt.gca().xaxis.set_major_locator(mdates.YearLocator(1))

    # Set ticks font size
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)

    # Add faint gridlines with thin lines
    plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray', alpha=0.3)

    # Rotate x-axis labels for better readability
    plt.gcf().autofmt_xdate()

    # Adjust the layout
    plt.tight_layout()

    # Show the plot
    plt.show()

# Get the unique city names
cities = lepto_df['adm3_en'].unique()

# Define the features to compare against case_total
features = ['pr', 'tave', 'tmax', 'tmin', 'rh']

# Initialize the MinMaxScaler to scale features between 0 and 1
scaler = MinMaxScaler()

# Loop through each city
for city in cities:
    # Filter the dataframe for the specific city
    city_data = lepto_df[lepto_df['adm3_en'] == city]

    # Scale the data for comparison
    scaled_data = pd.DataFrame(scaler.fit_transform(city_data[['case_total'] + features]),
                               columns=['case_total'] + features,
                               index=city_data.index)

    # Loop through each feature to create pairwise plots
    for feature in features:
        # Set up the figure
        plt.figure(figsize=(12, 8))  # Increase figure size for better visibility

        # Plot case_total
        plt.plot(scaled_data.index, scaled_data['case_total'], label='Leptospirosis Cases', color='#19535B')

        # Plot the current feature with a thinner solid line
        plt.plot(scaled_data.index, scaled_data[feature], label=feature, color='#1477EA', linewidth=1.5)

        # Set the title and labels
        plt.title(f'{city}: Leptospirosis Cases vs. {feature}', fontsize=16)
        plt.ylabel('Scaled Values', fontsize=14)
        plt.xlabel('Date', fontsize=14)

        # Format the x-axis to show dates by year
        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        plt.gca().xaxis.set_major_locator(mdates.YearLocator(1))

        # Set the x-axis limits (expand the x-axis)
        date_range = pd.date_range(start=scaled_data.index.min(), end=scaled_data.index.max())
        plt.xlim(date_range[0], date_range[-1])

        # Set ticks font size
        plt.xticks(fontsize=12)
        plt.yticks(fontsize=12)

        # Add faint gridlines with thin lines
        plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray', alpha=0.3)

        # Rotate x-axis labels for better readability
        plt.gcf().autofmt_xdate()

        # Adjust the layout
        plt.tight_layout()

        # Add a legend
        plt.legend(loc='upper right')

        # Show the plot
        plt.show()

# Get the unique city names
cities = lepto_df['adm3_en'].unique()

# Define the features to compare against case_total
features = ['pr', 'tave', 'tmax', 'tmin', 'rh','heat_index']

# Initialize the MinMaxScaler to scale features between 0 and 1
scaler = MinMaxScaler()

# Loop through each city
for city in cities:
    # Filter the dataframe for the specific city
    city_data = lepto_df[lepto_df['adm3_en'] == city]

    # Scale the data for comparison
    scaled_data = pd.DataFrame(scaler.fit_transform(city_data[['case_total'] + features]),
                               columns=['case_total'] + features,
                               index=city_data.index)

    # Loop through each feature to create pairwise plots
    for feature in features:
        # Set up the figure with a larger size
        plt.figure(figsize=(16, 12))  # Further increase figure size for better visibility

        # Plot case_total with a thicker line
        plt.plot(scaled_data.index, scaled_data['case_total'], label='Leptospirosis Cases', color='#19535B', linewidth=2.5)

        # Plot the current feature with a thinner solid line
        plt.plot(scaled_data.index, scaled_data[feature], label=feature, color='#1477EA', linewidth=1.0)

        # Set the title and labels
        plt.title(f'{city}: Leptospirosis Cases vs. {feature}', fontsize=18)

        # Format the x-axis to show dates by year
        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        plt.gca().xaxis.set_major_locator(mdates.YearLocator(1))

        # Set the x-axis limits to include some padding
        date_range = pd.date_range(start=scaled_data.index.min(), end=scaled_data.index.max())
        plt.xlim(date_range[0] - pd.DateOffset(months=6), date_range[-1] + pd.DateOffset(months=6))

        # Set ticks font size and rotation
        plt.xticks(fontsize=18, rotation=0)
        plt.yticks(fontsize=18)

        # Add faint gridlines with thin lines
        plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray', alpha=0.3)

        # Adjust the layout
        plt.tight_layout()

        # Add a legend
        plt.legend(loc='upper left', fontsize=18)

        # Show the plot
        plt.show()